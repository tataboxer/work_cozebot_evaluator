#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import requests
import json
import os
import sys
import time
from datetime import datetime
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆ›å»ºå…¨å±€é”ä¿æŠ¤CSVå†™å…¥
csv_lock = threading.Lock()

def parse_context_simple(context_str):
    """ç®€å•è§£æcontextå­—ç¬¦ä¸²ä¸ºPythonå¯¹è±¡"""
    if not context_str or context_str.strip() == '':
        return None
    
    try:
        # ç›´æ¥è§£æJSONæ•°ç»„ï¼ˆç°åœ¨æ•°æ®ç”Ÿæˆæ—¶å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼‰
        context_data = json.loads(context_str)
        return context_data if isinstance(context_data, list) else None
    except json.JSONDecodeError as e:
        print(f"âš ï¸ Contextè§£æå¤±è´¥: {e}")
        return None

def evaluate_with_llm(question, answer, context=None):
    """è°ƒç”¨LLM APIè¿›è¡Œè¯„ä¼°"""

    # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
    context_text = ""
    if context:
        context_data = None
        if isinstance(context, str):
            context_data = parse_context_simple(context)
        elif isinstance(context, list):
            context_data = context
        
        if context_data and len(context_data) > 0:
            context_text = "\nå¯¹è¯å†å²:\n"
            for i, msg in enumerate(context_data):
                role = "ç”¨æˆ·" if msg.get('role') == 'user' else "åŠ©æ‰‹"
                content = msg.get('content', '')
                context_text += f"{i+1}. {role}: {content}\n"
            context_text += "\n"

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIè¯„ä¼°ä¸“å®¶ï¼Œç°åœ¨éœ€è¦è¯„ä¼°è‹å·ç§‘æŠ€é¦†æ•°å­—äººåŠ©æ‰‹è¶£æ³¢ï¼ˆQuBooï¼‰çš„å›å¤è´¨é‡ã€‚

èƒŒæ™¯ï¼šè¶£æ³¢æ˜¯è‹å·ç§‘æŠ€é¦†çš„AIæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºæ¸¸å®¢æä¾›ç§‘æŠ€é¦†å‚è§‚ã€ç¥¨åŠ¡ã€å±•å…ã€æ´»åŠ¨ç­‰ç›¸å…³ä¿¡æ¯å’ŒæœåŠ¡ï¼Œå¸®åŠ©æ¸¸å®¢è·å¾—ä¼˜è´¨çš„ç§‘æŠ€ä½“éªŒã€‚

å¯¹è¯å†å²: {context_text}
ç”¨æˆ·é—®é¢˜: {question}
åŠ©æ‰‹å›å¤: {answer}

è¯·ä»ä»¥ä¸‹ä¸‰ä¸ªè§’åº¦è¯„ä¼°å›å¤è´¨é‡ï¼š

1. æœ€ç»ˆå‡†ç¡®ç‡ï¼šå›å¤å†…å®¹æ˜¯å¦å‡†ç¡®å›ç­”äº†ç”¨æˆ·é—®é¢˜ï¼Œæ˜¯å¦è§£å†³äº†ç”¨æˆ·çš„æŸ¥è¯¢éœ€æ±‚ï¼Œæ˜¯å¦ä¸ç§‘æŠ€é¦†ä¸šåŠ¡ç›®æ ‡é«˜åº¦è´´åˆã€‚{"è€ƒè™‘ä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼Œä½†ä¸éœ€è¦è¯„åˆ¤å¯¹è¯å†å²ç”¨assistantçš„å›å¤" if context_text else ""} è¯„åˆ†1-100åˆ†ã€‚

2. ä¸“ä¸šåº¦ï¼šç”¨è¯æ˜¯å¦ç²¾å‡†ã€æœ¯è¯­æ˜¯å¦æ­£ç¡®ã€ä¸šåŠ¡ä¸Šä¸‹æ–‡æ˜¯å¦ç¬¦åˆç§‘æŠ€é¦†åœºæ™¯çš„ä¸“ä¸šæ°´å‡†ã€‚è¯„åˆ†1-100åˆ†ã€‚

3. è¯­æ°”åˆç†ï¼šè¯­æ°”æ˜¯å¦ç¤¼è²Œå‹å¥½ã€é£æ ¼æ˜¯å¦åŒ¹é…ç§‘æŠ€é¦†æ•°å­—åŠ©æ‰‹åœºæ™¯ï¼ˆäº²åˆ‡ã€å¼•å¯¼æ€§ã€ä¸“ä¸šä½†ä¸ç”Ÿç¡¬ï¼‰ã€‚è¯„åˆ†1-100åˆ†ã€‚

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼š
{{
  "æœ€ç»ˆå‡†ç¡®ç‡": {{"åˆ†æ•°": æ•°å­—, "ç†ç”±": "ç®€è¦è¯´æ˜"}},
  "ä¸“ä¸šåº¦": {{"åˆ†æ•°": æ•°å­—, "ç†ç”±": "ç®€è¦è¯´æ˜"}},
  "è¯­æ°”åˆç†": {{"åˆ†æ•°": æ•°å­—, "ç†ç”±": "ç®€è¦è¯´æ˜"}}
}}"""

    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    llm_url = os.getenv('llm_url')
    llm_api_key = os.getenv('llm_api_key')
    llm_model_name = os.getenv('llm_model_name')

    if not all([llm_url, llm_api_key, llm_model_name]):
        raise ValueError("ç¯å¢ƒå˜é‡é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

    api_url = f"{llm_url}chat/completions"

    headers = {
        'Authorization': f'Bearer {llm_api_key}',
        'Content-Type': 'application/json'
    }

    data = {
        'model': llm_model_name,
        'messages': [{'role': 'user', 'content': prompt}],
        'temperature': 0.1
    }

    max_retries = 3
    for attempt in range(max_retries):
        try:
            print(f"æ­£åœ¨è¯„ä¼°é—®é¢˜: {question[:30]}{'...' if len(question) > 30 else ''}")
            response = requests.post(api_url, headers=headers, json=data, timeout=60)

            if response.status_code == 200:
                result = response.json()['choices'][0]['message']['content']

                # å¤„ç†markdownæ ¼å¼
                if '```json' in result:
                    json_match = result.split('```json')[1].split('```')[0].strip()
                    return json.loads(json_match)
                else:
                    return json.loads(result)
            elif response.status_code == 429:
                # APIé™æµï¼Œç­‰å¾…åé‡è¯•
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                print(f"APIé™æµï¼Œç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œç­‰å¾…{wait_time}ç§’...")
                time.sleep(wait_time)
                continue
            else:
                print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return None

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                print(f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸ï¼Œç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œç­‰å¾…{wait_time}ç§’: {e}")
                time.sleep(wait_time)
                continue
            else:
                print(f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}")
                return None

    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›None
    print(f"è¯„ä¼°å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    return None

def process_single_row(row_data, csv_file_path):
    """å¤„ç†å•è¡Œæ•°æ®çš„å‡½æ•°ï¼ˆç”¨äºå¹¶å‘å¤„ç†ï¼‰"""
    index, row = row_data
    question = str(row['question_text'])
    answer = str(row['block_result'])
    
    # è·å–ä¸Šä¸‹æ–‡æ•°æ®
    context = None
    if 'context' in row and pd.notna(row['context']) and str(row['context']).strip():
        context = str(row['context'])

    # è·³è¿‡ç©ºå†…å®¹
    if not answer or answer.strip() == '':
        print(f"è·³è¿‡ç¬¬{index+1}è¡Œ: å›å¤å†…å®¹ä¸ºç©º")
        return {'index': index, 'success': False, 'error': 'ç©ºå†…å®¹'}

    # æ˜¾ç¤ºcontextä¿¡æ¯
    context_info = " (æ— ä¸Šä¸‹æ–‡)"
    if context:
        context_data = parse_context_simple(context)
        if context_data and isinstance(context_data, list):
            context_info = f" (å«{len(context_data)}æ¡ä¸Šä¸‹æ–‡)"
        else:
            context_info = " (ä¸Šä¸‹æ–‡æ ¼å¼é”™è¯¯)"
    print(f"\n[{index+1}] æ­£åœ¨å¤„ç†é—®é¢˜: {question[:30]}{'...' if len(question) > 30 else ''}{context_info}")

    # æ·»åŠ éšæœºå»¶æ—¶é¿å…APIé™æµï¼ˆ1-3ç§’ï¼‰
    delay = 1 + (index % 3)
    time.sleep(delay)

    # è°ƒç”¨LLMè¯„ä¼°
    evaluation = evaluate_with_llm(question, answer, context)

    if evaluation:
        try:
            # ä½¿ç”¨é”ä¿æŠ¤CSVå†™å…¥æ“ä½œ
            with csv_lock:
                # é‡æ–°è¯»å–æœ€æ–°æ•°æ®ï¼ˆå› ä¸ºå…¶ä»–çº¿ç¨‹å¯èƒ½å·²ç»æ›´æ–°äº†ï¼‰
                df = pd.read_csv(csv_file_path, encoding='utf-8-sig')

                # å¡«å……è¯„ä¼°ç»“æœ
                df.at[index, 'æœ€ç»ˆå‡†ç¡®ç‡_åˆ†æ•°'] = evaluation['æœ€ç»ˆå‡†ç¡®ç‡']['åˆ†æ•°']
                df.at[index, 'æœ€ç»ˆå‡†ç¡®ç‡_ç†ç”±'] = evaluation['æœ€ç»ˆå‡†ç¡®ç‡']['ç†ç”±']
                df.at[index, 'ä¸“ä¸šåº¦_åˆ†æ•°'] = evaluation['ä¸“ä¸šåº¦']['åˆ†æ•°']
                df.at[index, 'ä¸“ä¸šåº¦_ç†ç”±'] = evaluation['ä¸“ä¸šåº¦']['ç†ç”±']
                df.at[index, 'è¯­æ°”åˆç†_åˆ†æ•°'] = evaluation['è¯­æ°”åˆç†']['åˆ†æ•°']
                df.at[index, 'è¯­æ°”åˆç†_ç†ç”±'] = evaluation['è¯­æ°”åˆç†']['ç†ç”±']

                # ç«‹å³å†™å…¥æ–‡ä»¶
                df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')

            print(f"âœ“ è¯„ä¼°æˆåŠŸ - å‡†ç¡®ç‡:{evaluation['æœ€ç»ˆå‡†ç¡®ç‡']['åˆ†æ•°']} ä¸“ä¸šåº¦:{evaluation['ä¸“ä¸šåº¦']['åˆ†æ•°']} è¯­æ°”:{evaluation['è¯­æ°”åˆç†']['åˆ†æ•°']}")
            return {'index': index, 'success': True, 'evaluation': evaluation}

        except KeyError as e:
            print(f"âœ— è¯„ä¼°ç»“æœæ ¼å¼é”™è¯¯: {e}")
            return {'index': index, 'success': False, 'error': f'æ ¼å¼é”™è¯¯: {e}'}
    else:
        print(f"âœ— è¯„ä¼°å¤±è´¥")
        return {'index': index, 'success': False, 'error': 'è¯„ä¼°å¤±è´¥'}

def process_csv_evaluation(csv_file_path):
    """å¤„ç†CSVæ–‡ä»¶å¹¶æ·»åŠ è¯„ä¼°ç»“æœ"""

    print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {csv_file_path}")

    # è¯»å–CSVæ–‡ä»¶
    try:
        df = pd.read_csv(csv_file_path, encoding='utf-8-sig')
    except UnicodeDecodeError:
        df = pd.read_csv(csv_file_path, encoding='gbk')

    print(f"åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}")
    print(f"åŸå§‹åˆ—å: {list(df.columns)}")

    # åˆå§‹åŒ–æ–°åˆ—ï¼ˆä»…å½“åˆ—ä¸å­˜åœ¨æ—¶ï¼‰
    if 'æœ€ç»ˆå‡†ç¡®ç‡_åˆ†æ•°' not in df.columns:
        df['æœ€ç»ˆå‡†ç¡®ç‡_åˆ†æ•°'] = None
    if 'æœ€ç»ˆå‡†ç¡®ç‡_ç†ç”±' not in df.columns:
        df['æœ€ç»ˆå‡†ç¡®ç‡_ç†ç”±'] = None
    if 'ä¸“ä¸šåº¦_åˆ†æ•°' not in df.columns:
        df['ä¸“ä¸šåº¦_åˆ†æ•°'] = None
    if 'ä¸“ä¸šåº¦_ç†ç”±' not in df.columns:
        df['ä¸“ä¸šåº¦_ç†ç”±'] = None
    if 'è¯­æ°”åˆç†_åˆ†æ•°' not in df.columns:
        df['è¯­æ°”åˆç†_åˆ†æ•°'] = None
    if 'è¯­æ°”åˆç†_ç†ç”±' not in df.columns:
        df['è¯­æ°”åˆç†_ç†ç”±'] = None

    # ç­›é€‰éœ€è¦è¯„ä¼°çš„è¡Œï¼šblock_type=answer ä¸” block_subtypeä¸ºæ–‡æœ¬å›å¤ ä¸” æ²¡æœ‰è¯„ä¼°æ•°æ®
    # åªæœ‰å½“æ‰€æœ‰è¯„ä¼°åˆ—éƒ½æœ‰æ•°æ®æ—¶æ‰è·³è¿‡ï¼Œå¦åˆ™éœ€è¦é‡æ–°è¯„ä¼°
    evaluation_rows = df[
        (df['block_type'] == 'answer') &
        (df['block_subtype'] == 'æ–‡æœ¬å›å¤') &
        (
            df['æœ€ç»ˆå‡†ç¡®ç‡_åˆ†æ•°'].isna() | 
            df['æœ€ç»ˆå‡†ç¡®ç‡_ç†ç”±'].isna() |
            df['ä¸“ä¸šåº¦_åˆ†æ•°'].isna() |
            df['ä¸“ä¸šåº¦_ç†ç”±'].isna() |
            df['è¯­æ°”åˆç†_åˆ†æ•°'].isna() |
            df['è¯­æ°”åˆç†_ç†ç”±'].isna()
        )
    ]

    print(f"éœ€è¦è¯„ä¼°çš„è¡Œæ•°: {len(evaluation_rows)}")
    print(f"å·²æœ‰è¯„ä¼°æ•°æ®çš„è¡Œæ•°: {len(df) - len(evaluation_rows)}")
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºç­›é€‰æ¡ä»¶çš„è¯¦ç»†æƒ…å†µ
    answer_rows = df[df['block_type'] == 'answer']
    text_reply_rows = df[(df['block_type'] == 'answer') & (df['block_subtype'] == 'æ–‡æœ¬å›å¤')]
    
    print(f"è°ƒè¯•ä¿¡æ¯:")
    print(f"  - æ€»è¡Œæ•°: {len(df)}")
    print(f"  - block_type=answer çš„è¡Œæ•°: {len(answer_rows)}")
    print(f"  - block_subtype=æ–‡æœ¬å›å¤ çš„è¡Œæ•°: {len(text_reply_rows)}")
    
    # æ£€æŸ¥å·²è¯„ä¼°çš„è¡Œ
    fully_evaluated = df[
        (df['block_type'] == 'answer') &
        (df['block_subtype'] == 'æ–‡æœ¬å›å¤') &
        (~df['æœ€ç»ˆå‡†ç¡®ç‡_åˆ†æ•°'].isna()) &
        (~df['æœ€ç»ˆå‡†ç¡®ç‡_ç†ç”±'].isna()) &
        (~df['ä¸“ä¸šåº¦_åˆ†æ•°'].isna()) &
        (~df['ä¸“ä¸šåº¦_ç†ç”±'].isna()) &
        (~df['è¯­æ°”åˆç†_åˆ†æ•°'].isna()) &
        (~df['è¯­æ°”åˆç†_ç†ç”±'].isna())
    ]
    print(f"  - å®Œå…¨è¯„ä¼°è¿‡çš„æ–‡æœ¬å›å¤è¡Œæ•°: {len(fully_evaluated)}")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œçš„è¯„ä¼°çŠ¶æ€æ ·ä¾‹
    if len(text_reply_rows) > 0:
        print(f"\nå‰3è¡Œæ–‡æœ¬å›å¤çš„è¯„ä¼°çŠ¶æ€:")
        for i, (idx, row) in enumerate(text_reply_rows.head(3).iterrows()):
            accuracy_score = row.get('æœ€ç»ˆå‡†ç¡®ç‡_åˆ†æ•°', 'N/A')
            accuracy_reason = row.get('æœ€ç»ˆå‡†ç¡®ç‡_ç†ç”±', 'N/A')
            professional_score = row.get('ä¸“ä¸šåº¦_åˆ†æ•°', 'N/A')
            tone_score = row.get('è¯­æ°”åˆç†_åˆ†æ•°', 'N/A')
            print(f"  è¡Œ{idx+1}: å‡†ç¡®ç‡={accuracy_score}, ä¸“ä¸šåº¦={professional_score}, è¯­æ°”={tone_score}, ç†ç”±={'æœ‰' if pd.notna(accuracy_reason) and str(accuracy_reason).strip() else 'æ— '}")

    if len(evaluation_rows) == 0:
        print("âœ… æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„è¡Œéƒ½å·²æœ‰è¯„ä¼°æ•°æ®ï¼Œè·³è¿‡è¯„ä¼°")
        return csv_file_path  # è¿”å›åŸæ–‡ä»¶è·¯å¾„

    # ä»ç¯å¢ƒå˜é‡è¯»å–çº¿ç¨‹æ•°é…ç½®ï¼Œé»˜è®¤ä¸º5
    max_workers = int(os.getenv('ASSESS_THREADS', 5))
    print(f"å¼€å§‹ä½¿ç”¨{max_workers}ä¸ªçº¿ç¨‹å¹¶å‘å¤„ç† {len(evaluation_rows)} è¡Œæ•°æ®...")
    print(f"ğŸ“Š é…ç½®ä¿¡æ¯: æœ€å¤§è¯„ä¼°çº¿ç¨‹æ•° = {max_workers}")

    # ä½¿ç”¨ThreadPoolExecutorå¹¶å‘å¤„ç†
    evaluated_count = 0
    success_count = 0

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_task = {
            executor.submit(process_single_row, (index, row), csv_file_path): index
            for index, row in evaluation_rows.iterrows()
        }

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future in as_completed(future_to_task):
            task_index = future_to_task[future]
            try:
                result = future.result()
                evaluated_count += 1

                if result['success']:
                    success_count += 1
                else:
                    print(f"ä»»åŠ¡ {task_index+1} å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

                # æ˜¾ç¤ºè¿›åº¦
                print(f"è¿›åº¦: {evaluated_count}/{len(evaluation_rows)} å·²å®Œæˆ")

            except Exception as exc:
                print(f'å¤„ç†ç¬¬ {task_index+1} è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {exc}')
                evaluated_count += 1

    print("\n" + "="*60)
    print("ğŸ‰ å¹¶å‘è¯„ä¼°å®Œæˆï¼")
    print("="*60)
    print(f"æ–‡ä»¶å·²æ›´æ–°: {csv_file_path}")
    print(f"æ€»è¡Œæ•°: {len(df)}")
    print(f"è¯„ä¼°è¡Œæ•°: {evaluated_count}")
    print(f"æˆåŠŸè¯„ä¼°: {success_count}")
    print(f"æˆåŠŸç‡: {(success_count/evaluated_count*100):.1f}%" if evaluated_count > 0 else "0%")
    print(f"å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")

    return csv_file_path

def main():
    print("=" * 60)
    print("LLM å›å¤è´¨é‡è¯„ä¼°å·¥å…·")
    print("=" * 60)

    if len(sys.argv) != 2:
        print("ç”¨æ³•: python assess.py <csv_file_path>")
        print("ç¤ºä¾‹: python assess.py data/results_20250918_184058.csv")
        sys.exit(1)

    csv_file = sys.argv[1]

    if not os.path.exists(csv_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
        sys.exit(1)

    # æ£€æŸ¥.envæ–‡ä»¶
    if not os.path.exists('.env'):
        print("âŒ æœªæ‰¾åˆ° .env æ–‡ä»¶ï¼Œè¯·ç¡®ä¿åŒ…å«ä»¥ä¸‹é…ç½®:")
        print("  llm_url=https://api-inference.modelscope.cn/v1/")
        print("  llm_api_key=your_api_key")
        print("  llm_model_name=Qwen/Qwen3-Coder-480B-A35B-Instruct")
        sys.exit(1)

    try:
        output_file = process_csv_evaluation(csv_file)
        print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()